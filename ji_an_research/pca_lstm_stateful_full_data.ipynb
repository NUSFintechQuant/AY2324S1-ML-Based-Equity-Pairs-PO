{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lstm_functions import *\n",
    "from lost_functions import *\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import yfinance as yf\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'data/scrapped_data'\n",
    "\n",
    "# Get all .csv files in the directory\n",
    "all_files = os.listdir(directory)\n",
    "csv_files = [f for f in all_files if f.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['CSCO', 'UAL', 'TROW', 'ISRG', 'NVR', 'TPR', 'DVN', 'CE', 'MRO', 'BA', 'VRTX', 'GILD', 'EQIX', 'TER', 'MDT', 'V', 'QRVO', 'A', 'FOX', 'FLT', 'MO', 'CTRA', 'SWKS', 'ENPH', 'MCHP', 'CDNS', 'MSCI', 'CHTR', 'EIX', 'BBY', 'WBA', 'LVS', 'HCA', 'AJG', 'DTE', 'C', 'T', 'CF', 'DISH', 'MGM', 'HUM', 'CBOE', 'CFG', 'WU', 'APH', 'SYY', 'MSI', 'FCX', 'ADM', 'LH', 'LNT', 'BAC', 'LNC', 'PSX', 'GPN', 'PPG', 'TECH', 'IRM', 'IQV', 'ESS', 'HAL', 'STZ', 'DXC', 'ADI', 'F', 'ADBE', 'CPRT', 'TDG', 'TFX', 'ULTA', 'ARE', 'SYK', 'CB', 'TSN', 'GNRC', 'PEP', 'PEG', 'NOW', 'LLY', 'COST', 'REG', 'NWS', 'LOW', 'MDLZ', 'BKNG', 'ZBRA', 'FMC', 'XEL', 'AIZ', 'MET', 'FTV', 'DLR', 'XRAY', 'FAST', 'TJX', 'SNA', 'MPC', 'BR', 'D', 'MRK', 'STX', 'NOC', 'BXP', 'KHC', 'IPG', 'UNP', 'ALLE', 'ABBV', 'CDAY', 'ORCL', 'ECL', 'ETR', 'EBAY', 'SBUX', 'PENN', 'IR', 'AMT', 'INTU', 'DPZ', 'PAYC', 'CMA', 'IPGP', 'PG', 'CAT', 'ODFL', 'MCD', 'MNST', 'AMZN', 'INTC', 'PNR', 'GLW', 'BDX', 'KMI', 'PWR', 'APTV', 'BBWI', 'DXCM', 'EXR', 'WELL', 'HOLX', 'EXPD', 'GM', 'TXN', 'VRSK', 'SJM', 'TMO', 'OXY', 'RL', 'CCI', 'MMM', 'MOS', 'FTNT', 'HSY', 'JNPR', 'DHI', 'ED', 'ES', 'ADSK', 'GL', 'IP', 'EXPE', 'KO', 'PCAR', 'WDC', 'LUMN', 'PYPL', 'NEE', 'UPS', 'LEG', 'EMR', 'MSFT', 'ANSS', 'CTAS', 'BIO', 'UDR', 'CTLT', 'WEC', 'AME', 'IT', 'DD', 'ACN', 'VRSN', 'EW', 'CMG', 'AWK', 'COO', 'SHW', 'HPQ', 'AMAT', 'CCL', 'MLM', 'AVY', 'AAP', 'ATVI', 'EVRG', 'EA', 'DE', 'SPG', 'AMD', 'KLAC', 'NDAQ', 'URI', 'WHR', 'RTX', 'NXPI', 'PNC', 'KMX', 'WRK', 'MTCH', 'BIIB', 'NVDA', 'CHRW', 'ROP', 'IDXX', 'EXC', 'HES', 'HD', 'ALB', 'VLO', 'AON', 'ZTS', 'FDX', 'DG', 'TYL', 'HIG', 'CMS', 'CAG', 'INCY', 'SCHW', 'HSIC', 'AZO', 'AXP', 'HPE', 'DFS', 'SEE', 'HRL', 'SO', 'FRT', 'ZBH', 'CME', 'XOM', 'AMP', 'CVX', 'CMCSA', 'PNW', 'ICE', 'BEN', 'UHS', 'BKR', 'EMN', 'SBAC', 'ROK', 'PTC', 'NRG', 'NSC', 'NKE', 'FIS', 'FANG', 'VTR', 'MAS', 'RF', 'ETSY', 'AMCR', 'TAP', 'MAR', 'XYL', 'CMI', 'MTD', 'KR', 'PLD', 'IBM', 'USB', 'BSX', 'LKQ', 'LIN', 'ITW', 'EOG', 'PVH', 'KMB', 'PEAK', 'SPGI', 'NEM', 'WFC', 'CTVA', 'EL', 'GS', 'GD', 'CNP', 'PM', 'MCO', 'CLX', 'CAH', 'MPWR', 'DGX', 'AVB', 'DIS', 'CBRE', 'GE', 'HII', 'LDOS', 'ALL', 'ETN', 'ALGN', 'NFLX', 'LEN', 'FITB', 'WST', 'GWW', 'NTRS', 'CVS', 'AOS', 'FE', 'ABC', 'JPM', 'ABT', 'OMC', 'COF', 'TSCO', 'PH', 'HST', 'JBHT', 'MRNA', 'TSLA', 'ATO', 'COP', 'DHR', 'CNC', 'MCK', 'TXT', 'MTB', 'VTRS', 'AKAM', 'ROL', 'RMD', 'WRB', 'GOOGL', 'BRO', 'ANET', 'PAYX', 'ALK', 'DRI', 'ILMN', 'AAL', 'MAA', 'MMC', 'FOXA', 'POOL', 'CZR', 'FFIV', 'VNO', 'CINF', 'VMC', 'MKTX', 'SRE', 'LHX', 'ORLY', 'IVZ', 'RCL', 'PXD', 'SNPS', 'GOOG', 'YUM', 'LYV', 'PFE', 'AVGO', 'DUK', 'REGN', 'CL', 'VFC', 'UA', 'VZ', 'JCI', 'AMGN', 'TEL', 'JKHY', 'ADP', 'STT', 'RSG', 'IFF', 'GPS', 'TRMB', 'QCOM', 'LYB', 'GIS', 'PHM', 'ROST', 'LUV', 'LW', 'MS', 'CPB', 'OKE', 'BK', 'J', 'SYF', 'CHD', 'HWM', 'MHK', 'TFC', 'DAL', 'APA', 'K', 'AFL', 'CSX', 'NI', 'PFG', 'NCLH', 'ZION', 'RJF', 'HBAN', 'UNH', 'PRU', 'GPC', 'WMB', 'EQR', 'DVA', 'AIG', 'MA', 'HBI', 'HON', 'O', 'NWSA', 'TTWO', 'AES', 'SLB', 'TT', 'TGT', 'AAPL', 'MKC', 'TDY', 'WY', 'APD', 'GRMN', 'AEE', 'HLT', 'DLTR', 'STE', 'HAS', 'TMUS', 'WMT', 'NTAP', 'KIM', 'BAX', 'LMT', 'ABMD', 'KEY', 'KEYS', 'BMY', 'PSA', 'WYNN', 'RHI', 'EFX', 'NUE', 'PKG', 'WAB', 'CTSH', 'SWK', 'CRL', 'MU', 'TRV', 'L', 'AEP', 'CI', 'DOW', 'CDW', 'JNJ', 'WM', 'DOV', 'CRM', 'PGR', 'WAT', 'IEX', 'BWA', 'LRCX', 'NWL', 'UAA', 'BLK', 'PPL'])\n"
     ]
    }
   ],
   "source": [
    "all_data = {}\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    # Get the name of the stock (which is the filename without the .csv extension)\n",
    "    stock_name = os.path.splitext(csv_file)[0]\n",
    "    \n",
    "    # Read the csv file\n",
    "    data = pd.read_csv(os.path.join(directory, csv_file))\n",
    "    data['Date'] = pd.to_datetime(data['Date'])\n",
    "    data = data.set_index('Date')\n",
    "    # resampled_data = data.resample('Y').last().reset_index()\n",
    "    original_data = data.reset_index()\n",
    "    all_data[stock_name] = original_data\n",
    "\n",
    "print(all_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Log Returns</th>\n",
       "      <th>RSI</th>\n",
       "      <th>ATR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>16.410000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>16.959999</td>\n",
       "      <td>11.685604</td>\n",
       "      <td>40980600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.728481</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>16.850000</td>\n",
       "      <td>17.299999</td>\n",
       "      <td>16.750000</td>\n",
       "      <td>17.110001</td>\n",
       "      <td>11.788960</td>\n",
       "      <td>45480200</td>\n",
       "      <td>0.008806</td>\n",
       "      <td>44.728481</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-06</td>\n",
       "      <td>17.330000</td>\n",
       "      <td>17.980000</td>\n",
       "      <td>17.260000</td>\n",
       "      <td>17.790001</td>\n",
       "      <td>12.257485</td>\n",
       "      <td>58256600</td>\n",
       "      <td>0.038973</td>\n",
       "      <td>44.728481</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-07</td>\n",
       "      <td>17.370001</td>\n",
       "      <td>17.580000</td>\n",
       "      <td>17.110001</td>\n",
       "      <td>17.320000</td>\n",
       "      <td>11.933647</td>\n",
       "      <td>50246600</td>\n",
       "      <td>-0.026775</td>\n",
       "      <td>44.728481</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-08</td>\n",
       "      <td>17.230000</td>\n",
       "      <td>17.570000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.540001</td>\n",
       "      <td>12.085232</td>\n",
       "      <td>46484600</td>\n",
       "      <td>0.012622</td>\n",
       "      <td>44.728481</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       Open       High        Low      Close  Adj Close    Volume  \\\n",
       "0 2009-01-02  16.410000  17.000000  16.250000  16.959999  11.685604  40980600   \n",
       "1 2009-01-05  16.850000  17.299999  16.750000  17.110001  11.788960  45480200   \n",
       "2 2009-01-06  17.330000  17.980000  17.260000  17.790001  12.257485  58256600   \n",
       "3 2009-01-07  17.370001  17.580000  17.110001  17.320000  11.933647  50246600   \n",
       "4 2009-01-08  17.230000  17.570000  17.000000  17.540001  12.085232  46484600   \n",
       "\n",
       "   Log Returns        RSI  ATR  \n",
       "0          NaN  44.728481  0.0  \n",
       "1     0.008806  44.728481  0.0  \n",
       "2     0.038973  44.728481  0.0  \n",
       "3    -0.026775  44.728481  0.0  \n",
       "4     0.012622  44.728481  0.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['CSCO'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CSCO</th>\n",
       "      <th>UAL</th>\n",
       "      <th>TROW</th>\n",
       "      <th>ISRG</th>\n",
       "      <th>NVR</th>\n",
       "      <th>TPR</th>\n",
       "      <th>DVN</th>\n",
       "      <th>CE</th>\n",
       "      <th>MRO</th>\n",
       "      <th>BA</th>\n",
       "      <th>...</th>\n",
       "      <th>CRM</th>\n",
       "      <th>PGR</th>\n",
       "      <th>WAT</th>\n",
       "      <th>IEX</th>\n",
       "      <th>BWA</th>\n",
       "      <th>LRCX</th>\n",
       "      <th>NWL</th>\n",
       "      <th>UAA</th>\n",
       "      <th>BLK</th>\n",
       "      <th>PPL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-05-28</th>\n",
       "      <td>5.742560</td>\n",
       "      <td>-3.101492</td>\n",
       "      <td>-2.941123</td>\n",
       "      <td>3.977873</td>\n",
       "      <td>4.209739</td>\n",
       "      <td>2.612609</td>\n",
       "      <td>3.672401</td>\n",
       "      <td>2.787215</td>\n",
       "      <td>2.292586</td>\n",
       "      <td>4.585790</td>\n",
       "      <td>...</td>\n",
       "      <td>4.939526</td>\n",
       "      <td>5.968055</td>\n",
       "      <td>3.749546</td>\n",
       "      <td>4.175739</td>\n",
       "      <td>0.474799</td>\n",
       "      <td>3.477087</td>\n",
       "      <td>-2.244693</td>\n",
       "      <td>0.768567</td>\n",
       "      <td>2.432493</td>\n",
       "      <td>-0.551553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-29</th>\n",
       "      <td>5.556673</td>\n",
       "      <td>-2.961172</td>\n",
       "      <td>-3.016342</td>\n",
       "      <td>3.933250</td>\n",
       "      <td>4.219512</td>\n",
       "      <td>2.536146</td>\n",
       "      <td>4.021113</td>\n",
       "      <td>2.862652</td>\n",
       "      <td>2.579049</td>\n",
       "      <td>4.438496</td>\n",
       "      <td>...</td>\n",
       "      <td>4.809965</td>\n",
       "      <td>5.990602</td>\n",
       "      <td>3.663666</td>\n",
       "      <td>4.159149</td>\n",
       "      <td>0.422434</td>\n",
       "      <td>3.331694</td>\n",
       "      <td>-2.383500</td>\n",
       "      <td>0.671020</td>\n",
       "      <td>2.327289</td>\n",
       "      <td>-0.271027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-30</th>\n",
       "      <td>5.674830</td>\n",
       "      <td>-3.058444</td>\n",
       "      <td>-3.145513</td>\n",
       "      <td>4.033821</td>\n",
       "      <td>4.291905</td>\n",
       "      <td>2.714001</td>\n",
       "      <td>3.914470</td>\n",
       "      <td>2.914301</td>\n",
       "      <td>2.590401</td>\n",
       "      <td>4.443868</td>\n",
       "      <td>...</td>\n",
       "      <td>4.892576</td>\n",
       "      <td>6.082325</td>\n",
       "      <td>3.672284</td>\n",
       "      <td>4.202720</td>\n",
       "      <td>0.310862</td>\n",
       "      <td>3.435586</td>\n",
       "      <td>-2.402307</td>\n",
       "      <td>0.656765</td>\n",
       "      <td>2.336810</td>\n",
       "      <td>-0.199948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-31</th>\n",
       "      <td>5.283546</td>\n",
       "      <td>-2.856948</td>\n",
       "      <td>-2.844767</td>\n",
       "      <td>3.813620</td>\n",
       "      <td>4.210843</td>\n",
       "      <td>2.654546</td>\n",
       "      <td>3.928847</td>\n",
       "      <td>2.580194</td>\n",
       "      <td>2.807813</td>\n",
       "      <td>4.259111</td>\n",
       "      <td>...</td>\n",
       "      <td>4.726087</td>\n",
       "      <td>5.921675</td>\n",
       "      <td>3.599236</td>\n",
       "      <td>4.208028</td>\n",
       "      <td>0.553490</td>\n",
       "      <td>3.284177</td>\n",
       "      <td>-2.471258</td>\n",
       "      <td>0.632961</td>\n",
       "      <td>2.101701</td>\n",
       "      <td>-0.114303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-03</th>\n",
       "      <td>5.218577</td>\n",
       "      <td>-2.884312</td>\n",
       "      <td>-2.471279</td>\n",
       "      <td>3.694799</td>\n",
       "      <td>4.374227</td>\n",
       "      <td>2.586957</td>\n",
       "      <td>3.793778</td>\n",
       "      <td>2.569843</td>\n",
       "      <td>2.714616</td>\n",
       "      <td>4.112392</td>\n",
       "      <td>...</td>\n",
       "      <td>4.449071</td>\n",
       "      <td>5.920239</td>\n",
       "      <td>3.556064</td>\n",
       "      <td>4.269690</td>\n",
       "      <td>0.398818</td>\n",
       "      <td>3.205809</td>\n",
       "      <td>-2.360422</td>\n",
       "      <td>0.675346</td>\n",
       "      <td>2.145099</td>\n",
       "      <td>-0.270231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24</th>\n",
       "      <td>4.528247</td>\n",
       "      <td>-3.778037</td>\n",
       "      <td>-5.202313</td>\n",
       "      <td>5.668613</td>\n",
       "      <td>5.883938</td>\n",
       "      <td>2.746525</td>\n",
       "      <td>3.127041</td>\n",
       "      <td>4.913191</td>\n",
       "      <td>2.194773</td>\n",
       "      <td>4.164945</td>\n",
       "      <td>...</td>\n",
       "      <td>5.050904</td>\n",
       "      <td>5.051427</td>\n",
       "      <td>4.836394</td>\n",
       "      <td>5.210768</td>\n",
       "      <td>-1.093609</td>\n",
       "      <td>7.708492</td>\n",
       "      <td>-1.234440</td>\n",
       "      <td>0.213665</td>\n",
       "      <td>3.776071</td>\n",
       "      <td>-3.522287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>4.460317</td>\n",
       "      <td>-3.752110</td>\n",
       "      <td>-5.289247</td>\n",
       "      <td>5.644636</td>\n",
       "      <td>5.831584</td>\n",
       "      <td>2.671834</td>\n",
       "      <td>3.185776</td>\n",
       "      <td>4.816622</td>\n",
       "      <td>2.252053</td>\n",
       "      <td>4.031953</td>\n",
       "      <td>...</td>\n",
       "      <td>5.037988</td>\n",
       "      <td>4.936749</td>\n",
       "      <td>4.790517</td>\n",
       "      <td>5.194602</td>\n",
       "      <td>-1.011697</td>\n",
       "      <td>7.661096</td>\n",
       "      <td>-1.277436</td>\n",
       "      <td>0.220990</td>\n",
       "      <td>3.819172</td>\n",
       "      <td>-3.400410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>4.425738</td>\n",
       "      <td>-3.675666</td>\n",
       "      <td>-5.239472</td>\n",
       "      <td>5.629947</td>\n",
       "      <td>5.791137</td>\n",
       "      <td>2.761027</td>\n",
       "      <td>3.379824</td>\n",
       "      <td>4.814851</td>\n",
       "      <td>2.342484</td>\n",
       "      <td>4.006162</td>\n",
       "      <td>...</td>\n",
       "      <td>5.027544</td>\n",
       "      <td>4.973646</td>\n",
       "      <td>4.780315</td>\n",
       "      <td>5.176829</td>\n",
       "      <td>-0.989948</td>\n",
       "      <td>7.613757</td>\n",
       "      <td>-1.304755</td>\n",
       "      <td>0.215615</td>\n",
       "      <td>3.813293</td>\n",
       "      <td>-3.408152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>4.347413</td>\n",
       "      <td>-3.606835</td>\n",
       "      <td>-5.122394</td>\n",
       "      <td>5.562392</td>\n",
       "      <td>5.757856</td>\n",
       "      <td>2.863804</td>\n",
       "      <td>3.414140</td>\n",
       "      <td>4.763848</td>\n",
       "      <td>2.359675</td>\n",
       "      <td>3.920394</td>\n",
       "      <td>...</td>\n",
       "      <td>4.976048</td>\n",
       "      <td>4.974005</td>\n",
       "      <td>4.769360</td>\n",
       "      <td>5.133344</td>\n",
       "      <td>-0.939322</td>\n",
       "      <td>7.502904</td>\n",
       "      <td>-1.329096</td>\n",
       "      <td>0.148008</td>\n",
       "      <td>3.757418</td>\n",
       "      <td>-3.465939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>4.377221</td>\n",
       "      <td>-3.560061</td>\n",
       "      <td>-4.987342</td>\n",
       "      <td>5.494823</td>\n",
       "      <td>5.708509</td>\n",
       "      <td>2.818951</td>\n",
       "      <td>3.349472</td>\n",
       "      <td>4.692118</td>\n",
       "      <td>2.351251</td>\n",
       "      <td>3.827130</td>\n",
       "      <td>...</td>\n",
       "      <td>4.917424</td>\n",
       "      <td>4.948853</td>\n",
       "      <td>4.712669</td>\n",
       "      <td>5.077479</td>\n",
       "      <td>-0.891547</td>\n",
       "      <td>7.476110</td>\n",
       "      <td>-1.333099</td>\n",
       "      <td>0.159210</td>\n",
       "      <td>3.753472</td>\n",
       "      <td>-3.547108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows Ã— 477 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                CSCO       UAL      TROW      ISRG       NVR       TPR  \\\n",
       "Date                                                                     \n",
       "2019-05-28  5.742560 -3.101492 -2.941123  3.977873  4.209739  2.612609   \n",
       "2019-05-29  5.556673 -2.961172 -3.016342  3.933250  4.219512  2.536146   \n",
       "2019-05-30  5.674830 -3.058444 -3.145513  4.033821  4.291905  2.714001   \n",
       "2019-05-31  5.283546 -2.856948 -2.844767  3.813620  4.210843  2.654546   \n",
       "2019-06-03  5.218577 -2.884312 -2.471279  3.694799  4.374227  2.586957   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2019-12-24  4.528247 -3.778037 -5.202313  5.668613  5.883938  2.746525   \n",
       "2019-12-26  4.460317 -3.752110 -5.289247  5.644636  5.831584  2.671834   \n",
       "2019-12-27  4.425738 -3.675666 -5.239472  5.629947  5.791137  2.761027   \n",
       "2019-12-30  4.347413 -3.606835 -5.122394  5.562392  5.757856  2.863804   \n",
       "2019-12-31  4.377221 -3.560061 -4.987342  5.494823  5.708509  2.818951   \n",
       "\n",
       "                 DVN        CE       MRO        BA  ...       CRM       PGR  \\\n",
       "Date                                                ...                       \n",
       "2019-05-28  3.672401  2.787215  2.292586  4.585790  ...  4.939526  5.968055   \n",
       "2019-05-29  4.021113  2.862652  2.579049  4.438496  ...  4.809965  5.990602   \n",
       "2019-05-30  3.914470  2.914301  2.590401  4.443868  ...  4.892576  6.082325   \n",
       "2019-05-31  3.928847  2.580194  2.807813  4.259111  ...  4.726087  5.921675   \n",
       "2019-06-03  3.793778  2.569843  2.714616  4.112392  ...  4.449071  5.920239   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "2019-12-24  3.127041  4.913191  2.194773  4.164945  ...  5.050904  5.051427   \n",
       "2019-12-26  3.185776  4.816622  2.252053  4.031953  ...  5.037988  4.936749   \n",
       "2019-12-27  3.379824  4.814851  2.342484  4.006162  ...  5.027544  4.973646   \n",
       "2019-12-30  3.414140  4.763848  2.359675  3.920394  ...  4.976048  4.974005   \n",
       "2019-12-31  3.349472  4.692118  2.351251  3.827130  ...  4.917424  4.948853   \n",
       "\n",
       "                 WAT       IEX       BWA      LRCX       NWL       UAA  \\\n",
       "Date                                                                     \n",
       "2019-05-28  3.749546  4.175739  0.474799  3.477087 -2.244693  0.768567   \n",
       "2019-05-29  3.663666  4.159149  0.422434  3.331694 -2.383500  0.671020   \n",
       "2019-05-30  3.672284  4.202720  0.310862  3.435586 -2.402307  0.656765   \n",
       "2019-05-31  3.599236  4.208028  0.553490  3.284177 -2.471258  0.632961   \n",
       "2019-06-03  3.556064  4.269690  0.398818  3.205809 -2.360422  0.675346   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2019-12-24  4.836394  5.210768 -1.093609  7.708492 -1.234440  0.213665   \n",
       "2019-12-26  4.790517  5.194602 -1.011697  7.661096 -1.277436  0.220990   \n",
       "2019-12-27  4.780315  5.176829 -0.989948  7.613757 -1.304755  0.215615   \n",
       "2019-12-30  4.769360  5.133344 -0.939322  7.502904 -1.329096  0.148008   \n",
       "2019-12-31  4.712669  5.077479 -0.891547  7.476110 -1.333099  0.159210   \n",
       "\n",
       "                 BLK       PPL  \n",
       "Date                            \n",
       "2019-05-28  2.432493 -0.551553  \n",
       "2019-05-29  2.327289 -0.271027  \n",
       "2019-05-30  2.336810 -0.199948  \n",
       "2019-05-31  2.101701 -0.114303  \n",
       "2019-06-03  2.145099 -0.270231  \n",
       "...              ...       ...  \n",
       "2019-12-24  3.776071 -3.522287  \n",
       "2019-12-26  3.819172 -3.400410  \n",
       "2019-12-27  3.813293 -3.408152  \n",
       "2019-12-30  3.757418 -3.465939  \n",
       "2019-12-31  3.753472 -3.547108  \n",
       "\n",
       "[152 rows x 477 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []  # List to hold individual DataFrames for each stock's transformed data\n",
    "\n",
    "# Loop over each stock in the all_data dictionary\n",
    "for stock, data in all_data.items():\n",
    "    data = data.dropna()\n",
    "    # Drop non-numeric columns, like 'Date' and 'Sector'\n",
    "    numeric_data = data.drop(columns=['Date'])\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(numeric_data)\n",
    "    \n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=1)\n",
    "    transformed_data = pca.fit_transform(scaled_data)\n",
    "    \n",
    "    # Create a new DataFrame for the transformed data and set its column name to the stock\n",
    "    df_stock = pd.DataFrame(transformed_data, columns=[stock], index=data['Date'])\n",
    "    dfs.append(df_stock)\n",
    "\n",
    "# Concatenate all individual DataFrames to create the all_stock DataFrame\n",
    "all_stock = pd.concat(dfs, axis=1)\n",
    "\n",
    "all_stock = all_stock.dropna()\n",
    "all_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_train, train_predictions, y_test, test_predictions, ticker, feature):\n",
    "    train_mae = mean_absolute_error(y_train, train_predictions)\n",
    "    test_mae = mean_absolute_error(y_test, test_predictions)\n",
    "\n",
    "    train_rmse = mean_squared_error(y_train, train_predictions, squared=False)\n",
    "    test_rmse = mean_squared_error(y_test, test_predictions, squared=False)\n",
    "\n",
    "    print(f\"\\nEvaluation for {ticker} on {feature}:\")\n",
    "    print(f\"Training MAE: {train_mae}, Testing MAE: {test_mae}\")\n",
    "    print(f\"Training RMSE: {train_rmse}, Testing RMSE: {test_rmse}\\n\")\n",
    "    return train_mae, test_mae, train_rmse, test_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(y_train, train_predictions, y_test, test_predictions, ticker, feature):\n",
    "    plt.figure(figsize=(14,7))\n",
    "    plt.plot(y_train, label=\"Actual Train Values\", color='blue')\n",
    "    plt.plot(train_predictions, label=\"Predicted Train Values\", color='blue', linestyle='dashed')\n",
    "    plt.plot(np.arange(len(y_train), len(y_train) + len(y_test)), y_test, label=\"Actual Test Values\", color='red')\n",
    "    plt.plot(np.arange(len(y_train), len(y_train) + len(y_test)), test_predictions, label=\"Predicted Test Values\", color='red', linestyle='dashed')\n",
    "    plt.title(f\"{ticker} {feature} - Actual vs Predicted Values\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_importance_values = {}\n",
    "final_predictions = {}\n",
    "# 30 is not a good number of batches, but it's a start for testing\n",
    "# 60 is a good number of batches, but it takes a long time to train\n",
    "time_steps = 60\n",
    "features = len(all_stock.columns)\n",
    "features\n",
    "batch_size_value = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-26 16:07:56.921777: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-10-26 16:07:56.921913: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-10-26 16:07:56.921961: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-10-26 16:07:56.922319: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-10-26 16:07:56.922383: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining:  0\n"
     ]
    }
   ],
   "source": [
    "data = all_stock.copy().dropna()\n",
    "lstm_model = LstmBuilder(time_step=time_steps, loss=\"mean_squared_error\", batch_size=batch_size_value)\n",
    "model = lstm_model.create_stateful_model(features=features)\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(data)\n",
    "X, y = lstm_model.create_sequences(normalized_data)\n",
    "X_train, X_test, y_train, y_test = lstm_model.split_stateful_data(X,y, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 60, 477), (12, 60, 477), (80, 477), (12, 477))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-26 16:08:03.359014: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jianyang/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Y3S1/NUS Fintech/AY2324S1-ML-Empowered-Stat-Arb/ji_an_research/pca_lstm_stateful_full_data.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jianyang/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Y3S1/NUS%20Fintech/AY2324S1-ML-Empowered-Stat-Arb/ji_an_research/pca_lstm_stateful_full_data.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49mbatch_size_value, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jianyang/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Y3S1/NUS%20Fintech/AY2324S1-ML-Empowered-Stat-Arb/ji_an_research/pca_lstm_stateful_full_data.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Extracting importance\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jianyang/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/Y3S1/NUS%20Fintech/AY2324S1-ML-Empowered-Stat-Arb/ji_an_research/pca_lstm_stateful_full_data.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m dense_weights \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mlayers[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mget_weights()[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniforge3/envs/nus_fintech/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=200, batch_size=batch_size_value, verbose=0)\n",
    "\n",
    "# Extracting importance\n",
    "dense_weights = model.layers[-1].get_weights()[0]\n",
    "\n",
    "# Think about to use sum or mean and to use abs() or not\n",
    "feature_weights = dense_weights.sum(axis=0)\n",
    "print(feature_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for both training and testing data\n",
    "train_predictions = scaler.inverse_transform(model.predict(X_train, batch_size=batch_size_value))\n",
    "test_predictions = scaler.inverse_transform(model.predict(X_test, batch_size=batch_size_value))\n",
    "y_train = scaler.inverse_transform(y_train)\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "features_list = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "for feature_index, feature_name in enumerate(data.columns):\n",
    "    # Extracting data for the specific feature\n",
    "    y_train_feature = y_train[:, feature_index]\n",
    "    y_test_feature = y_test[:, feature_index]\n",
    "    train_predictions_feature = train_predictions[:, feature_index]\n",
    "    test_predictions_feature = test_predictions[:, feature_index]\n",
    "\n",
    "    # Evaluating the model for this feature\n",
    "    evaluate_model(y_train_feature, train_predictions_feature, y_test_feature, test_predictions_feature, feature_name, feature_name)\n",
    "\n",
    "    # Plotting the results for this feature\n",
    "    plot_predictions(y_train_feature, train_predictions_feature, y_test_feature, test_predictions_feature, feature_name, feature_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_importance_values = dict(zip(data.columns, feature_weights))\n",
    "final_importance_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_values = np.array(list(final_importance_values.values()))\n",
    "importance_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run this if we want a arbitrage strategy\n",
    "Each weight will be -1 to 1, the sum is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Scale the values to [-1, 1]\n",
    "arbitrage_scaled_importance = 2 * (importance_values - np.min(importance_values)) / (np.max(importance_values) - np.min(importance_values)) - 1\n",
    "\n",
    "# 2. Ensure the sum is zero\n",
    "arbitrage_normalized_importance = arbitrage_scaled_importance - np.mean(arbitrage_scaled_importance)\n",
    "\n",
    "# Convert back to dictionary\n",
    "arbitrage_ticker_to_importance = dict(zip(final_importance_values.keys(), arbitrage_normalized_importance))\n",
    "\n",
    "print(arbitrage_ticker_to_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run this instead if we want a normal strategy\n",
    "Each weight will be 0 to 1, the sum is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))  # subtract max to avoid potential overflow\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "# Convert the importance values to probabilities using softmax\n",
    "probabilities = softmax(importance_values)\n",
    "\n",
    "# Convert back to dictionary\n",
    "normalized_ticker_to_importance = dict(zip(final_importance_values.keys(), probabilities))\n",
    "\n",
    "print(normalized_ticker_to_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance(normalized_ticker_to_importance = normalized_ticker_to_importance, title='Normalized Importance Values'):\n",
    "# Split the tickers and importance values based on positive and negative values\n",
    "    long_positions = {k: v for k, v in normalized_ticker_to_importance.items() if v > 0}\n",
    "    short_positions = {k: v for k, v in normalized_ticker_to_importance.items() if v <= 0}\n",
    "\n",
    "    # Sort the positions for better visualization\n",
    "    sorted_long = dict(sorted(long_positions.items(), key=lambda item: item[1], reverse=True))\n",
    "    sorted_short = dict(sorted(short_positions.items(), key=lambda item: item[1]))\n",
    "\n",
    "    # Create bar charts\n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "    # Positive cluster\n",
    "    bars_long = ax.bar(sorted_long.keys(), sorted_long.values(), color='g', label='Long')\n",
    "\n",
    "    # Negative cluster\n",
    "    bars_short = ax.bar(sorted_short.keys(), sorted_short.values(), color='r', label='Short')\n",
    "\n",
    "    # Rotate x-tick labels for better readability\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "    # Annotate the bars\n",
    "    for bar in bars_long:\n",
    "        yval = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, yval + 0.01, round(yval, 3), ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    for bar in bars_short:\n",
    "        yval = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, yval - 0.02, round(yval, 3), ha='center', va='top', fontsize=9)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel('Importance Value')\n",
    "    ax.set_xlabel('Ticker')\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the arbitrage importance values\n",
    "plot_importance(arbitrage_ticker_to_importance, title='Arbitrage Importance Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the importance values\n",
    "plot_importance(normalized_ticker_to_importance, title='Normalized Importance Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_data = yf.download('SPY')\n",
    "spy_monthly = spy_data.resample('M').last()\n",
    "spy_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the Portfolio and Backtest\n",
    "def build_portfolio(normalized_ticker_to_importance=normalized_ticker_to_importance, strategy='Normal'):\n",
    "    portfolio_returns = pd.DataFrame()\n",
    "    for ticker, importance in normalized_ticker_to_importance.items():\n",
    "        data = all_data[ticker].set_index('Date')\n",
    "        data['Returns'] = data['Adj Close'].pct_change().fillna(0)\n",
    "        portfolio_returns[ticker] = data['Returns'] * importance\n",
    "    portfolio_returns['Portfolio'] = portfolio_returns.sum(axis=1)\n",
    "    spy_monthly['SPY Returns'] = spy_monthly['Adj Close'].pct_change().fillna(0)\n",
    "    # Cumulative Returns\n",
    "    portfolio_returns['Cumulative Portfolio'] = (portfolio_returns['Portfolio'] + 1).cumprod() - 1\n",
    "    spy_monthly['Cumulative SPY'] = (spy_monthly['SPY Returns'] + 1).cumprod() - 1\n",
    "    combined = pd.concat([portfolio_returns['Cumulative Portfolio'], spy_monthly['Cumulative SPY']], axis=1).dropna()\n",
    "    print(combined)\n",
    "    # Plot\n",
    "    plt.figure(figsize=(14,7))\n",
    "    combined['Cumulative Portfolio'].plot(label=\"Portfolio\")\n",
    "    combined['Cumulative SPY'].plot(label=\"SPY\")\n",
    "    plt.legend()\n",
    "    plt.title(strategy + \" Portfolio vs. SPY Cumulative Returns\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the portfolio for arbitrage strategy\n",
    "build_portfolio(arbitrage_ticker_to_importance, strategy='Arbitrage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the portfolio for the Normal strategy\n",
    "build_portfolio(normalized_ticker_to_importance, strategy='Normal')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nus_fintech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
